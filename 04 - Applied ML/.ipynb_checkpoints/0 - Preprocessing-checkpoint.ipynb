{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# There's a lot of columns in the DF. \n",
    "# Therefore, we add this option so that we can see more columns\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "In this notebook, we will perform some cleaning and analysis of the data before applying the Machine Learning algorithm. \n",
    "\n",
    "First, let us load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/CrowdstormingDataJuly1st.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data description, which is the `Data.md` file in the `Data` folder, tells us that we are working on \n",
    "> a dataset of player–referee dyads including the number of matches players and referees encountered each other and our dependent variable, the number of red cards given to a player by a particular referee throughout all matches the two encountered each other.\n",
    "\n",
    "A dyad between a player and a referee simply means the interaction between a player and a referee. \n",
    "\n",
    "\n",
    "## 1. Cleaning the NaNs values for the colours of players\n",
    "\n",
    "We want to see the number of entries in the Dataframe before starting to clean the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_size_init = df.shape\n",
    "print(df_size_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step we want to take is to remove all the players from which the skin column was not identified, i.e. the ones who have NaN entries in the *rater1* and *rater2* columns, which measures the darkness of the skin color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['rater1', 'rater2'])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see now that we dropped already quite some entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_size_init[0] - df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check for other null values\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still quite few entries that have null values, and we want to assess if they are correlated in any fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df[df['meanIAT'].isnull()].shape)\n",
    "print(df[df['meanExp'].isnull()].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see first that there is exactly the same number of entries having NaN *meanIAT* and *meanExp* entries, and we see below that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df['meanExp'].isnull()].refNum.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are only a few referees (the names are not here for anonymization purposes), that have NaN entries in both field. Let's just remove the them from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[~df['meanIAT'].isnull()]\n",
    "print(df.isnull().any())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that there are still some columns with NaN entries, which we will deal with later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Uniquely defining the skin column : creating a `skin_colour` column\n",
    "\n",
    "We define the skin_colour column as the mean of the *rater1* and *rater2* columns. They are described as the following  :\n",
    "\n",
    ">rater1 - skin rating of photo by rater 1 (5-point scale ranging from “very light skin” to “very dark skin”)\n",
    "\n",
    ">rater2 - skin rating of photo by rater 2 (5-point scale ranging from “very light skin” to “very dark skin”).\n",
    "\n",
    "As both describe the same thing with different scales, it is sensible to average them. We then remove the *rater1* and *rater2* columns, as they will not be of use for us anymore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['skin_colour'] = df[['rater1', 'rater2']].mean(axis=1)\n",
    "df = df.drop(['rater1', 'rater2'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us quickly check all the different `skin_colour` values that a player can have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_colours = df['skin_colour'].unique()\n",
    "np.sort(unique_colours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the 5 values that were initially given by the *rater1* and *rater2* columns, along with the values inbetween those, leading us to a grand total of 9 different entries (still from “very light skin” to “very dark skin”)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Removing some more features\n",
    "\n",
    "There are many columns that do not convey useful information to our purpose, we want to identify and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some very obvious entries that are of no use to us : \n",
    "- *photoID*: We do not have the pictures !\n",
    "- *refNum*: We will aggregate the values by the name of the player, so we do not need it.\n",
    "- *refCountry*: We do not need it for the same reason.\n",
    "- *Alpha_3*: We do not need it for the same reason.\n",
    "\n",
    "The following features only are related to a referee, and we will remove them as well.\n",
    "- *meanIAT*\n",
    "- *nIAT*\n",
    "- *seIAT*\n",
    "- *meanExp*\n",
    "- *nExp*\n",
    "- *seExp*\n",
    "\n",
    "**N.B.** We are doing this as the aim of the exercise is to determine the skin colour of a player from the stats we have on him. His skin colour should not depend on the referee present in his matches ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_to_remove = ['photoID', 'refNum', 'refCountry', 'Alpha_3', 'meanIAT', 'nIAT', 'seIAT', 'meanExp', 'nExp', 'seExp']\n",
    "df_cleaned = df.drop(columns_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df_cleaned.shape)\n",
    "df_cleaned.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did not change the number of entries here, but now only have 17 columns remaining. The following transformation is to get all the data related to each player, i.e. aggregate by their name.\n",
    "\n",
    "## 4. Aggregating the table\n",
    "\n",
    "The number of unique `player` entries is our database is way smaller than the total number of entries !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Total number of players: \", len(df_cleaned['player'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that have extensive data on a few players, as they played many matches in their career. We will now perform the aggregation of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_players = df_cleaned['player'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the DataFrame in which we'll store our unique player entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Values on whichc we want to sum\n",
    "summed = ['games', 'victories', 'ties', 'defeats', 'goals', \n",
    "         'yellowCards', 'yellowReds', 'redCards']\n",
    "#Dirty trick to keep the NaNs in the groupby because there is no other was to do so (opened issue in the project)\n",
    "df_players = df_cleaned.replace(np.nan, -1000).groupby(['playerShort', 'player' ,'club' ,'leagueCountry', 'birthday', 'height', 'weight','position','skin_colour'])\n",
    "df_players = df_players[summed].sum()\n",
    "df_players = df_players.reset_index().replace(-1000, np.NaN)\n",
    "print(df_players.shape)\n",
    "\n",
    "df_players_no_nan = df_players.dropna()\n",
    "print(df_players_no_nan.shape)\n",
    "\n",
    "df_players.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that if we don't keep the NaNs, we lose many players in the process. We want to see whether it is justified to do so. We computed all the players which are exluded of our newer DataFrame. First of all, we just want to note that that there are a few players who have the same name, so the sorting by the *playerShort* attribute will yield unique results. One such example is the following :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check whether the entries are unique for the playerShort attribute\n",
    "print(len(df_players.playerShort) - len(df_players.playerShort.unique()))\n",
    "\n",
    "#Check whether the entries are unique for the player attribute\n",
    "print(len(df_players.player) - len(df_players.player.unique()))\n",
    "\n",
    "df_players.loc[df_players.player == ' Juanfran']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now focus on the players which were excluded from the aggregation. There are three distinct cases for the exclusion of players from the DataFrame, as we show below. Either\n",
    "- the player has no *weight* entry,\n",
    "- the player has no *position* entry,\n",
    "- the player has no *height* entry,\n",
    "- or it can be a combination of those. \n",
    "\n",
    "Let us show a player with no *position entry*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a player with both no *weight*, no *height* and no *position* !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_players.loc[df_players['height'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that removing them is the simplest approach we can take, but let us first check the percentage of the population that they represent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Percentage of people removed with the aggregation: \", 100*(1-df_players_no_nan.shape[0]/len(df_cleaned.playerShort.unique())), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if they represent 10% of our population, we can remove them as including them in the Machine Learning process would yield many complications, having to create special cases for each of the missing data. We will however keep them in a separate DataFrame for comparison's sake.\n",
    "\n",
    "We also discretise the country in which they're playing and the birthYear in order to be able to use it in our algrithm, as it only takes numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_players['english'] = [int(country == 'England') for country in df_players['leagueCountry']]\n",
    "df_players['german'] = [int(country == 'Germany') for country in df_players['leagueCountry']]\n",
    "df_players['french'] = [int(country == 'France') for country in df_players['leagueCountry']]\n",
    "df_players['spanish'] = [int(country == 'Spain') for country in df_players['leagueCountry']]\n",
    "df_players['birthYear'] = [int(b[-4:]) for b in df_players['birthday']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We now save these DataFrames, making sure before that there are no more NaNs in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df_players_no_nan.isnull().any())\n",
    "\n",
    "#actualise the value of the DataFrame\n",
    "df_players_no_nan = df_players.dropna()\n",
    "\n",
    "df_players.to_csv('./Data/players.csv', index=False)\n",
    "df_players_no_nan.to_csv('./Data/players_no_nan.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also save the dataFrames with only the numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_numeric = ['playerShort', 'player', 'club', 'leagueCountry', 'birthday', 'position']\n",
    "df_players.drop(non_numeric, axis=1).to_csv('./Data/players_num_values.csv', index=False)\n",
    "df_players_no_nan.drop(non_numeric, axis=1).to_csv('./Data/players_no_nan_only_num_values.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cross-Featuring\n",
    "\n",
    "We can introduce some cross-features with the features we removed. We know for example that the columns with\n",
    "- **IAT** refer to the **race IAT test**, *i.e.* a high value correspond to someone who will prefer a white person (thinks it's a better person) over a black person.\n",
    "- **Exp** refer to the use of a **racial thermometer task**, *i.e.* a high value corresponds to greater feelings of warmth toward whites versus blacks.\n",
    "\n",
    "If we want to keep these information, we can cross-feature those information with the yellow and red cards given to the player . \n",
    "\n",
    "Let's introduce a **new variable**. We will call it the `gravity_factor`. It is given by:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "G = Y + \\frac{\\sum Y}{\\sum YR}  YR + \\frac{\\sum Y }{\\sum R} R\n",
    "\\end{equation}\n",
    "where:\n",
    "- $Y$ is the number of yellow cards given to a player\n",
    "- $\\sum Y$ is the total number of yellow cards given\n",
    "- $YR$ is the number of yellow then red cards given to a player\n",
    "- $\\sum YR$ is the total number of yellow then red cards given\n",
    "- $R$ is the number of red cards given to a player\n",
    "- $\\sum R$ is the total number of red cards given\n",
    "\n",
    "\n",
    "So, let's add this new value to the big DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Percentage of yellow cards: \", 100*df['yellowCards'].sum()/\n",
    "      df['games'].sum(), \"%\")\n",
    "print(\"Percentage of yellow then red cards: \", 100*df['yellowReds'].sum()/\n",
    "      df['games'].sum(), \"%\")\n",
    "print(\"Percentage of red cards: \", 100*df['redCards'].sum()/\n",
    "      df['games'].sum(), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nbr_yellow = df['yellowCards'].sum()\n",
    "nbr_yellowRed = df['yellowReds'].sum()\n",
    "nbr_red = df['redCards'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gravity = df['yellowCards'] + nbr_yellow/nbr_yellowRed * df['yellowReds'] + nbr_yellow/nbr_red * df['redCards']\n",
    "gravity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_with_features = df\n",
    "df_with_features['gravity'] = gravity\n",
    "df_with_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gravity_players = df_players['yellowCards'] + nbr_yellow/nbr_yellowRed * df_players['yellowReds'] + nbr_yellow/nbr_red * df_players['redCards']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_players_with_features = df_players\n",
    "df_players_with_features['gravity'] = gravity_players\n",
    "df_players_with_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just check that the aggregation is correct\n",
    "print(\"Gravity for 1st player in aggregated table: \", df_players_with_features['gravity'][0])\n",
    "print(\"Gravity for 1st player in aggregated table: \", \n",
    "      df_with_features[df_with_features['player'] == 'Lucas Wilchez']['gravity'].sum())\n",
    "\n",
    "# It's ok.. =)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now introduce another cross-feature. The purpose of this one is to use the *meanIAT* and *meanExp* values. To do so, we will link them with the 4 following features: *yellowCards*, *yellowReds*, *redCards*, and *gravity*. We will use the following equation:\n",
    "\n",
    "\\begin{equation}\n",
    "F_{I-C} (P) = \\frac{1}{\\#R(P)} \\sum_{r\\in R(P)} \\frac{C(r)}{E(r)} \\cdot I(r)\n",
    "\\end{equation}\n",
    "\n",
    "where:\n",
    "- $F_{I-C} (P)$ defines the new feature.\n",
    "- $I$ is the indicator. It can be *meanIAT* or *meanExp*\n",
    "- $C$ defines the types of card received. It can be *yellowCards*, *yellowReds*, *redCards*, or *gravity*\n",
    "- $P$ is a given player.\n",
    "- $\\#R(P)$ is the number of referees with whom a player played.\n",
    "- $\\sum_{r\\in R(P)}$ is the sum over all referees who played with a given player.\n",
    "- $C(r)$ is the value of $C$ for a specific Player and a specific referee.\n",
    "- $E(r)$ is the number of times a referee played with a player.\n",
    "- $I(r)$ is the indicator of the referee.\n",
    "\n",
    "This will create 8 new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indicators = ['meanIAT', 'meanExp']\n",
    "cards = ['yellowCards', 'yellowReds', 'redCards', 'gravity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idcts in indicators:\n",
    "    for crds in cards:\n",
    "        feature_name = idcts + \"_\" + crds\n",
    "        array_feature = []\n",
    "        print(\"Start feature \", feature_name)\n",
    "        for plyr in df_players['player']:\n",
    "            feature = 0\n",
    "            # Get the DF with the player\n",
    "            df_player = df[df['player'] == plyr]\n",
    "            # Number of different referee\n",
    "            nbr_ref = len(df_player)\n",
    "            # Reindex\n",
    "            df_player.index = np.arange(nbr_ref)\n",
    "            # Sum for the new feature\n",
    "            for i in range(nbr_ref):\n",
    "                feature += df_player[crds][i]/df_player['games'][i]*df_player[idcts][i]\n",
    "            # Add it into the array\n",
    "            array_feature.append(feature/nbr_ref)\n",
    "        # Add it into the DataFrame\n",
    "        df_players_with_features[feature_name] = array_feature\n",
    "df_players_with_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's save the new DF\n",
    "df_players_with_features.to_csv('./Data/players_with features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can also save the one without the nan\n",
    "df_players_with_features_no_nan = df_players_with_features.dropna()\n",
    "df_players_with_features_no_nan.to_csv('./Data/players_with features_no_nan.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can remove all the columns with String values instead of numerical values.\n",
    "non_numeric = ['playerShort', 'player', 'club', 'leagueCountry', 'birthday', 'position']\n",
    "df_players_with_features.drop(non_numeric, axis=1).to_csv('./Data/players_with features_only_num_values.csv', index=False)\n",
    "df_players_with_features_no_nan.drop(non_numeric, axis=1).to_csv('./Data/players_with features_no_nan_only_num_values.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the data\n",
    "\n",
    "Let's do some scatter plot to see if some features are interesting with the *skin_colour*. We expect that some features such as the number of games played will be irrelevant with the *skin_colour*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_players_with_features_no_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_tmp = df_players_with_features.columns\n",
    "features = []\n",
    "label = 'skin_colour'\n",
    "for i in features_tmp:\n",
    "    if i != 'skin_colour':\n",
    "        features.append(i)\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ftre in features:\n",
    "    if ftre not in non_numeric:\n",
    "        plt.figure()\n",
    "        plt.scatter(list(df_players_with_features_no_nan[ftre]), list(df_players_with_features_no_nan[label]))\n",
    "        plt.title('Feature: %s'%(ftre))\n",
    "        plt.xlabel(ftre)\n",
    "        plt.ylabel(label)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just plot the values of meanExp because some values are less than 0\n",
    "plt.figure()\n",
    "plt.plot(df['meanExp'],color='b')\n",
    "plt.plot(df['meanIAT'],color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the data that are available did not seem to exhibit any obvious characteristic that would be correlated to the skin colour of a player. We will see whether our machine learning algorithm will be able to find a good classification."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
