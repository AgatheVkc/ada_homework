{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK 3  - INTERACTIVE VIZ\n",
    "\n",
    "** Build a Choropleth map which shows intuitively (i.e., use colors wisely) how much grant money goes to each Swiss canton. To do so, you will need to use the provided TopoJSON file, combined with the Choropleth map example you can find in the Folium README file.**\n",
    "\n",
    "**BONUS: using the map you have just built, and the geographical information contained in it, could you give a rough estimate of the difference in research funding between the areas divided by the Röstigraben?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get the canton to which each grant was assigned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usual imports first.\n",
    "- A INSTALLER AVEC pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.geocoders import GeoNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the grants and select a few useful attributes :\n",
    "- The university and the institution will try to help us locate the canton to which each grant was assigned.\n",
    "- The approved amount to know how much each canton received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_grants = pd.read_csv('P3_GrantExport.csv',sep=';')\n",
    "df_grants = df_grants[[6,7,11,12,13]]\n",
    "df_grants.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extracting the canton from the university field\n",
    "There are some issues in the data, that need to be formatted. First of all, some data need to be replaced with NaN, as they do not convey any information regarding the location of the grant that was assigned. We considered the following :\n",
    "- 'Nicht zuteilbar - NA' -> Unavailable data\n",
    "- 'NPO (Biblioth., Museen, Verwalt.) - NPO' -> No informations\n",
    "- 'Weitere Institute - FINST' -> Other institutes\n",
    "- 'Firmen/Privatwirtschaft - FP' -> Private institutions\n",
    "\n",
    "There is also a second part of data that simply have no university field. The location of where those grants were assigned then shall be determined in the second part of the extraction, where we turn our sights to the institution field of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_grants = df_grants.replace('Nicht zuteilbar - NA',np.nan)\n",
    "df_grants = df_grants.replace('NPO (Biblioth., Museen, Verwalt.) - NPO',np.nan)\n",
    "df_grants = df_grants.replace('Weitere Institute - FINST',np.nan)\n",
    "df_grants = df_grants.replace('Firmen/Privatwirtschaft - FP',np.nan)\n",
    "\n",
    "data_uni = df_grants['University'].unique()[1:]\n",
    "\n",
    "data_uni[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do a few less queries on the web to determine the location of our universities, we define two dictionnaries that we will extensively use to help us locate a university. The first one, `CANTON_DICT` associates each canton to its tag, that we will use on the map later on, but we can use it in the following way : if the key of this dict is present in the string describing the university, then we match it to the canton. It is very practical, as many universities are located in the capital of the canton, which often has the same name as the canton itself.\n",
    "\n",
    "The second dict, `CAPITAL_DICT` contains pairs associating the capital of a canton to a canton, for those who do not have exactly the same name. We will use it the same way as `CANTON_DICT` : if the name of the capital appears in the string of the university, we match it to the canton it belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CANTON_DICT = {'Zürich':'ZH','Bern':'BE','Luzern':'LU','Uri':'UR','Schwyz':'SZ','Obwalden':'OW','Nidwalden':'NW',\n",
    "               'Glarus':'GL','Zug':'ZG','Fribourg':'FR','Solothurn':'SO','Basel-Stadt':'BS','Basel-Landschaft':'BL',\n",
    "               'Schaffhausen':'SH','Appenzell Ausserrhoden':'AR','Appenzell Innerrhoden':'AI','Sankt Gallen':'SG',\n",
    "               'Graubünden':'GR','Aargau':'AG','Thurgau':'TG','Ticino':'TI', 'Vaud':'VD','Valais':'VS','Neuchâtel':'NE',\n",
    "               'Genève':'GE','Jura':'JU'}\n",
    "CAPITAL_DICT = {'Basel':'Basel-Stadt' ,'Lausanne':'Vaud', 'Sion':'Valais','Altdorf':'Uri','Sarnen':'Obwalden','Stans':'Nidwalden',\n",
    "                'Liestal':'Basel-Landschaft','Herisau':'Appenzell Ausserrhoden',\n",
    "                'Chur':'Graubünden','Aarau':'Aargau','Frauenfeld':'Thurgau','Bellinzona':'Ticino','Delémont':'Jura'}\n",
    "#'Appenzell':'Appenzell Innerrhoden' excluded because the name of the city is partially in the name of two cantons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now start with the canton extraction from the uni field. We will use two methods for that. \n",
    "- `extract_canton` will also be reused later on, tries to find, given a data_string containing a university/institution, the canton if belongs to. It does that in three steps :\n",
    "    1. Tries to see if a canton appears in the data_string\n",
    "    2. Tries to see if a capital which does not have the same name as the canton appears in the data_string\n",
    "    3. Queries the Nominatim web serviceto try to locate the string. Here, if the response if `None`, we return `None`, and if the answer is not in Switzerland (its last field should contain `Svizra` in this case), then we also return `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_canton(data_string):\n",
    "    \"\"\"\n",
    "        Fetchs from the web the location associated to a string. We use Nominatim at the moment. \n",
    "        The format of the output string (if it is not None) has the canton in the 6th output before the end.\n",
    "        The canton is written in all the languages spoken in it, and we hence split and keep the name that comes first.\n",
    "        @param data_string : the data from which we want to determine the canton\n",
    "        @return canton : the name of the canton associated to the input data_string\n",
    "    \"\"\"\n",
    "    for canton in CANTON_DICT:\n",
    "        if(canton in str(data_string)):\n",
    "            return canton\n",
    "    for city,canton in CAPITAL_DICT.items():\n",
    "        if(city in str(data_string)):\n",
    "            return canton\n",
    "    geolocator = Nominatim(country_bias='Switzerland')#,username='test_056')\n",
    "    location = geolocator.geocode(data_string)\n",
    "    split_loc = str(location).split(', ')\n",
    "    if (split_loc is not None) and (split_loc[-1] =='Svizra'):\n",
    "        canton = str(location).split(', ')\n",
    "        canton = canton[len(canton)-6]\n",
    "        return canton.split(' - ')[0]   \n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The second method, `extract_canton_from_uni`, will simply iterate on all the different universites of our DataFrame and call extract_canton. To get a higher chance of succeeding, we split the string at the `-` that separates the name and the acronym, and if the research was not successful with the full name, we pass the acronym to extract_canton as well. The full processing is done only once, and we store the result as a json file to load it again later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_canton_from_uni(data_uni):\n",
    "    \"\"\"\n",
    "        Extracts to which canton belongs a university and stored it into a json file (folder data).\n",
    "        @param data_uni :           an array of strings describing universities or other institutions.\n",
    "        @return university_dict :   a dict which associate to each university a canton if it was found\n",
    "                                    or a None if nothing was found.\n",
    "    \"\"\"\n",
    "    if(os.path.isfile('data/uni_canton_dict.json')):\n",
    "        print('Loading the data from json file')\n",
    "        with open('data/uni_canton_dict.json') as f:\n",
    "            university_dict = json.load(f)\n",
    "    else:\n",
    "        print('Fetching the locations from the web')\n",
    "        university_dict = dict()\n",
    "        for uni in data_uni:\n",
    "            # Splits the university string at the '-', which usually corresponds to the separation between the full name\n",
    "            # and the acronym of the institution.\n",
    "            uni_name_split = uni.split('-')\n",
    "            extract_value = extract_canton(uni_name_split[0])\n",
    "            if (extract_value is np.nan) and (len(uni_name_split) > 1):\n",
    "                # If the canton was not found in the name, then we try to extract it from the acronym string if it exists\n",
    "                extract_value = extract_canton(uni_name_split[1])\n",
    "            university_dict[uni] = extract_value\n",
    "        with open('data/uni_canton_dict.json', 'w') as f:\n",
    "            json.dump(university_dict, f)\n",
    "    return university_dict\n",
    "university_canton = extract_canton_from_uni(data_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now see the number of universities that were located and those who weren't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len([place for place, value in university_canton.items() if not pd.isnull(value)]))\n",
    "print(len([place for place, value in university_canton.items() if pd.isnull(value)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, this way only half of the universities were matches. Note that we did several tests and found that GeoNames leads a way poorer result than Nominatim (52 vs 37 not found), and prefiltering (trying to find the uni in the `CANTON_DICT` and `CAPITAL_DICT` dict) yields 37 not found against 40, but avoid queries on the web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now add a column to our grant DataFrame to find how many of the projects have been identified from their university name and fill this column with the canton tags from each canton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_grants['Canton'] = np.nan\n",
    "match_canton_uni = lambda uni: CANTON_DICT[university_canton[uni]] if (not pd.isnull(university_canton[uni]))  else university_canton[uni]\n",
    "df_grants.Canton = df_grants.University.loc[[uni in university_canton for uni  in df_grants.University]].apply(match_canton_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_grants.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(df_grants.Canton.isnull()/len(df_grants.Canton))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that only 30% of the cantons were found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extracting the canton from the institution field\n",
    "Let us now address the potential problems we will encounter by displaying all the grants that have no universities associated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_grants.Institution.loc[df_grants.University.isnull()].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that those institutions are mostly foreign universities or reasearch centers, that do not provide useful informations for our exercise. However, there are some swiss universities in the middle of it, so we will need to iterate through it and sort the institutions that will be kept or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_institution = df_grants['Institution'].loc[df_grants['Canton'].isnull()]\n",
    "df_institution = df_institution.unique()#head()\n",
    "print(df_institution.shape)\n",
    "\n",
    "INSTITUTION_EXCLUDED = ['USA','GB','AUS','CDN','Stanford University','University of Cambridge','Paris']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_canton_from_institution(data_institution, complete = True):\n",
    "    \"\"\"\n",
    "        Extracts to which canton belongs a institution and stored it into a json file (folder data). \n",
    "        As this data is very large, the queries to the website will most likely time out. We dump the the dictionnary \n",
    "        to a json file at each iteration and can restart from it with the parameter complete\n",
    "        @param data_institution :   an array of strings describing institutions.\n",
    "        @param complete         :   tells us if the process has been completed (everything saved to json file)\n",
    "        @return institution_dict :  a dict which associate to each university a canton if it was found\n",
    "                                    or a None if nothing was found.\n",
    "    \"\"\"\n",
    "    institution_dict = dict()\n",
    "    if(os.path.isfile('data/instit_canton_dict.json')):\n",
    "        print('Loading the data from json file')\n",
    "        with open('data/instit_canton_dict.json') as f:\n",
    "            institution_dict = json.load(f)\n",
    "        #print(institution_dict)\n",
    "    if not(os.path.isfile('data/instit_canton_dict.json') and complete):\n",
    "        print('Fetching the locations from the web')\n",
    "        excluded_bool = False\n",
    "        for index,instit in enumerate(data_institution):\n",
    "            for excluded in INSTITUTION_EXCLUDED:\n",
    "                if(not excluded_bool and excluded in str(instit))  :\n",
    "                    institution_dict[instit] = np.nan\n",
    "                    print(index,'- EXCLUDED <===== ',instit,)\n",
    "                    excluded_bool = True\n",
    "            if not excluded_bool:\n",
    "                value = extract_canton(instit)\n",
    "                institution_dict[instit] = value\n",
    "                if value is not np.nan:\n",
    "                    print(index,'-',value,'<=====',instit )\n",
    "                with open('data/instit_canton_dict.json', 'w') as f:\n",
    "                    json.dump(institution_dict, f)\n",
    "            excluded_bool = False\n",
    "    return institution_dict\n",
    "institution_canton = extract_canton_from_institution(df_institution[1995:],complete=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elements 1 - 1165 sampled with Nominatim :\n",
    "\n",
    "Should continue to do it, but I'm blocked\n",
    "\n",
    "Elements 1166 - 1512 with GeoNames\n",
    "\n",
    "1513 -1994 Nominatim\n",
    "\n",
    "1995 - 2815 GeoNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Gets the lengths of the dictionnary stored so we can know where to sample from (first number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('data/instit_canton_dict.json') as f:\n",
    "    institution_dict = json.load(f)\n",
    "#print(len(institution_dict))\n",
    "#for index,elem in enumerate(df_institution):\n",
    "#    if(elem == 'UNI: Université de Neuchâtel Institut de Mic rotechnique  Neuchâtel CH'):\n",
    "# print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
